{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Assignment-03.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AKHIL-882/Natural-Language-Processing/blob/main/Assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOpjHNuuEnlQ"
      },
      "source": [
        "# <center> Assignment-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUfSS2dHEnlY"
      },
      "source": [
        "1. Solve below assignment problems in the jupyter notebook only and submit the same on or before the deadline.\n",
        "* Naming convention for the jupyter notebook file should be <b>email_assignment_3.ipynb</b>\n",
        "* Do not copy & paste the code from online. If you do so, you will be rewarded with 0 score for the respective question.\n",
        "* If you have any queries, please post it in the assignments channel in Microsoft Teams.\n",
        "* You can refer to online resources for solving these questions but don’t copy the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_kKMffEnla"
      },
      "source": [
        "### <center> Problem-01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwlKmBIcEnla",
        "outputId": "5c8850c2-bded-4dcd-a73d-42ee96615dc3"
      },
      "source": [
        "\n",
        "'''\n",
        "    Write a funtion that takes a string as an input and...\n",
        "    Replace the characters in the string which are not lowercase characters,uppercase characters,digits with '+' (plus) character.\n",
        "    \n",
        "    Note: You have to use regular expressions.\n",
        "    \n",
        "    Sample Input:\n",
        "        # string= 'I am doing remote internship at IIIT-H and I am currently solving problem-03 in assignment-02'\n",
        "        \n",
        "    Sample Output:\n",
        "        # output= 'I+am+doing+remote+internship+at+IIIT+H+and+I+am+currently+solving+problem+03+in+assignment+02'\n",
        "    \n",
        "'''\n",
        "    \n",
        "    # Write your code here\n",
        "\n",
        "#Importing Re library\n",
        "import re\n",
        "\n",
        "def str_replace(string):\n",
        "\n",
        "  #inputing the string from user\n",
        "\n",
        "  new_string = input()\n",
        "\n",
        "  #using regular expression , replacing the character with + symbol\n",
        "\n",
        "  new_string = re.sub('[^a-zA-Z0-9 \\n\\.]', '+', new_string)\n",
        "\n",
        "  #printing the result with replacement\n",
        "\n",
        "  print(new_string.replace(\" \", \"+\")) \n",
        "  \n",
        "str_replace(new_string)\n",
        "\n",
        "\n",
        "# End of the code\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am doing remote internship at IIIT-H and I am currently solving problem-03 in assignment-02\n",
            "I+am+doing+remote+internship+at+IIIT+H+and+I+am+currently+solving+problem+03+in+assignment+02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex8UpvYNEnlc"
      },
      "source": [
        "### <center>Problem-02"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ZlTs9iEnld",
        "outputId": "ddb26f36-7184-4726-c2f9-c1688c48ff9a"
      },
      "source": [
        "# def tokenize_data(text, lang = \"english\"):\n",
        "'''\n",
        "    Write a funtion that takes a string, language as an input and...\n",
        "    return the list of sentences and list of tokens (words).\n",
        "    \n",
        "    Note: \n",
        "        --> You have to use regular expressions.\n",
        "        --> Tokens should not contain any leading/trailing (at the begining or ending of word) special characters (including punctuation).\n",
        "        --> For your reference, check the sample output here.\n",
        "        --> The list of languages are [\"english\", \"telugu\", \"hindi\"]. For all these languages' text the code should work.\n",
        "    \n",
        "    Sample Input:\n",
        "        ### Example -1\n",
        "        # string   = 'My name is Mr. V. V.S. Narayana. I am doing remote internship at IIIT - H. I am currently solving problem- 02 in assignment -03'\n",
        "        # language = \"english\"\n",
        "        \n",
        "        ### Example -2\n",
        "        # string   = \"హైదర్‌నగర్‌లో టీఆర్ఎస్ గెలిచింది. టీఆర్ఎస్ అభ్యర్థి నార్నె శ్రీనివాసరావు విజయం సాధించారు.\"\n",
        "        # language = \"telugu\"\n",
        "        \n",
        "        ### Example -3\n",
        "        # string   = \"मेरा नाम विक्रांत कुमार है। मैं हैदराबाद में इंटर्नशिप कर रहा हूं।\"\n",
        "        # language = \"hindi\"\n",
        "        \n",
        "    Sample Output:\n",
        "        ### Example -1\n",
        "        # sentences = ['My name is Mr. V. V.S. Narayana','I am doing remote internship at IIIT - H','I am currently solving problem- 02 in assignment -03']\n",
        "        # tokens    = ['My', 'name', 'is', 'Mr. V. V.S. Narayana', 'I', 'am', 'doing', 'remote', 'internship', 'at', 'IIIT - H', 'I', 'am', 'currently', 'solving', 'problem- 02', 'in', 'assignment -03']\n",
        "        \n",
        "        ### Example -2\n",
        "        # sentences = ['హైదర్నగర్లో టీఆర్ఎస్ గెలిచింది', 'టీఆర్ఎస్ అభ్యర్థి నార్నె శ్రీనివాసరావు విజయం సాధించారు']\n",
        "        # tokens    = ['హైదర్నగర్లో', 'టీఆర్ఎస్', 'గెలిచింది', 'టీఆర్ఎస్', 'అభ్యర్థి', 'నార్నె', 'శ్రీనివాసరావు', 'విజయం', 'సాధించారు']\n",
        "        \n",
        "        ### Example -3\n",
        "        # sentences = ['मेरा नाम विक्रांत कुमार है', 'मैं हैदराबाद में इंटर्नशिप कर रहा हूं']\n",
        "        # tokens    = ['मेरा', 'नाम', 'विक्रांत', 'कुमार', 'है', 'मैं', 'हैदराबाद', 'में', 'इंटर्नशिप', 'कर', 'रहा', 'हूं']\n",
        "    \n",
        "    HINT:\n",
        "        First split the given string into sentences and next divide each sentnece into tokens (words).\n",
        "    \n",
        "'''\n",
        "    # sentences = []\n",
        "    # tokens = []\n",
        "    # Write your code here\n",
        "    \n",
        "    \n",
        "    # End of the code\n",
        "    \n",
        "    #return sentences, tokens\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def tokenize_data(string):\n",
        "\n",
        "  lang = input(\"\")\n",
        "  new_string = input(\"\")\n",
        "  \n",
        "\n",
        "  sentences = []\n",
        "  tokens = []\n",
        "\n",
        "  print(\"The word tokenizser\")\n",
        "  tokens.append(word_tokenize(new_string))\n",
        "  print(tokens)\n",
        "\n",
        "  print(\"The sentence tokenizser\")\n",
        "  sentences.append(sent_tokenize(new_string))\n",
        "  print(sentences)\n",
        "\n",
        "tokenize_data(new_string)\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Enter the languagetelugu\n",
            "Enter the stringహైదర్నగర్లో టీఆర్ఎస్ గెలిచింది', 'టీఆర్ఎస్ అభ్యర్థి నార్నె శ్రీనివాసరావు విజయం సాధించారు\n",
            "The word tokenizser\n",
            "[['హైదర్నగర్లో', 'టీఆర్ఎస్', 'గెలిచింది', \"'\", ',', \"'టీఆర్ఎస్\", 'అభ్యర్థి', 'నార్నె', 'శ్రీనివాసరావు', 'విజయం', 'సాధించారు']]\n",
            "The sentence tokenizser\n",
            "[[\"హైదర్నగర్లో టీఆర్ఎస్ గెలిచింది', 'టీఆర్ఎస్ అభ్యర్థి నార్నె శ్రీనివాసరావు విజయం సాధించారు\"]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoFui-f5Enle"
      },
      "source": [
        "### <center> Problem-03"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7bkRrHoEnle",
        "outputId": "89f9c67f-ee1a-473d-b61a-8574608634bc"
      },
      "source": [
        "def extract_emails(email): \n",
        "  \n",
        "    \"\"\"\n",
        "    Write a function that takes a string as input and...\n",
        "    Returns list of all valid email addresses in the given string.\n",
        "    \n",
        "    Note: You have to use regular expressions. Do not copy the regular expression from any source (you have to write your own).\n",
        "    \n",
        "    Sample Input:\n",
        "        string: \"n20200@rguktn.ac.in and n1208595@rguktn.ac.in are email ids from rguktn domain.\"\n",
        "        \n",
        "    Sample Output:\n",
        "        \n",
        "        output: ['n20200@rguktn.ac.in', 'n1208595@rguktn.ac.in']\n",
        "\n",
        "    \"\"\"\n",
        "  ### write your code here\n",
        "    pattern = re.compile(r'[0-9a-zA-Z\\._]+@[a-zA-Z]+\\.[a-zA-Z]+[\\.]*[a-zA-Z]*')\n",
        "    output = pattern.findall(email)\n",
        "  ### end of code\n",
        "\n",
        "    return output\n",
        "\n",
        "email = input()\n",
        "extract_emails(email)\n",
        "\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n20200@rguktn.ac.in and n1208595@rguktn.ac.in are email ids from rguktn domain.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n20200@rguktn.ac.in', 'n1208595@rguktn.ac.in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XDZQKMJEnlf",
        "outputId": "88f3993b-8672-45e9-de36-b515e86aad27"
      },
      "source": [
        "# def stemming(string): \n",
        "  \n",
        "#     \"\"\"\n",
        "#     Write a function that takes a string as input and for each word in the string find it's stem\n",
        "#     Return a list with element as a tuple containing the word and it's stem\n",
        "    \n",
        "#     Note: You can use in-built stemmer\n",
        "    \n",
        "#     Sample Input:\n",
        "    \n",
        "#       #string='Pant goes to 100 with a six against England. He played beautifully and fans are cheering with loads of happiness'\n",
        "        \n",
        "#     Sample Output:\n",
        "    \n",
        "#       #output= [('Pant', 'pant'), ('goes', 'goe'), ('to', 'to'), ('100', '100'), ('with', 'with'), ('a', 'a'), ('six', 'six'), \n",
        "#       ('against', 'against'), ('England', 'england'), ('He', 'He'), ('played', 'play'), ('beautifully', 'beauti'),\n",
        "#       ('and', 'and'), ('fans', 'fan'), ('are', 'are'), ('cheering', 'cheer'), ('with', 'with'), ('loads', 'load'), \n",
        "#       ('of', 'of'), ('happiness', 'happi')]\n",
        "        \n",
        "#     \"\"\"\n",
        "#   ### write your code here\n",
        "    \n",
        "#   ### end of code\n",
        "#     return output\n",
        "\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "new_string = input()\n",
        "split_words = word_tokenize(new_string)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "for letters in split_words:\n",
        "\tstem_words=ps.stem(letters)\n",
        "\tprint(letters + \" \" + \" :\"  + \" \" + stem_words)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pant goes to 100 with a six against England. He played beautifully and fans are cheering with loads of happiness\n",
            "Pant  : pant\n",
            "goes  : goe\n",
            "to  : to\n",
            "100  : 100\n",
            "with  : with\n",
            "a  : a\n",
            "six  : six\n",
            "against  : against\n",
            "England  : england\n",
            ".  : .\n",
            "He  : He\n",
            "played  : play\n",
            "beautifully  : beauti\n",
            "and  : and\n",
            "fans  : fan\n",
            "are  : are\n",
            "cheering  : cheer\n",
            "with  : with\n",
            "loads  : load\n",
            "of  : of\n",
            "happiness  : happi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vutn9XPXEnlg"
      },
      "source": [
        "### <center> Problem-05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1_58HFGEnlg",
        "outputId": "3abf371d-dd20-449a-d987-10b2ba512b78"
      },
      "source": [
        "# def lemmatization(string): \n",
        "  \n",
        "#     \"\"\"\n",
        "#     Write a function that takes a string as input and for each word in the string find it's lemma\n",
        "#     Return a list with element as a tuple containing the word and it's lemma\n",
        "    \n",
        "#     Note: You can use in-built lemmatizer\n",
        "    \n",
        "#     Sample Input:\n",
        "#         #string='Pant goes to 100 with a six against England. He played beautifully and fans are cheering with loads of happiness'\n",
        "        \n",
        "#     Sample Output:\n",
        "#         # output= [('Pant', 'Pant'), ('goes', 'go'), ('to', 'to'), ('100', '100'), ('with', 'with'), ('a', 'a'), ('six', 'six'),\n",
        "#         ('against', 'against'), ('England', 'England'), ('He', 'He'), ('played', 'played'), ('beautifully', 'beautifully'), \n",
        "#         ('and', 'and'), ('fans', 'fan'), ('are', 'are'), ('cheering', 'cheering'), ('with', 'with'), ('loads', 'load'), \n",
        "#         ('of', 'of'), ('happiness', 'happiness')]\n",
        "        \n",
        "#     \"\"\"\n",
        "#   ### write your code here\n",
        "   \n",
        "#   ### end of code\n",
        "#     return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "# Create WordNetLemmatizer object\n",
        "Lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "# single word lemmatization examples\n",
        "new_string = input()\n",
        "for letters in new_string:\n",
        "    print(letters + \":\" + Lemmatizer.lemmatize(letters))"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "'Pant goes to 100 with a six against England. He played beautifully and fans are cheering with loads of happiness\n",
            "':'\n",
            "P:P\n",
            "a:a\n",
            "n:n\n",
            "t:t\n",
            " : \n",
            "g:g\n",
            "o:o\n",
            "e:e\n",
            "s:s\n",
            " : \n",
            "t:t\n",
            "o:o\n",
            " : \n",
            "1:1\n",
            "0:0\n",
            "0:0\n",
            " : \n",
            "w:w\n",
            "i:i\n",
            "t:t\n",
            "h:h\n",
            " : \n",
            "a:a\n",
            " : \n",
            "s:s\n",
            "i:i\n",
            "x:x\n",
            " : \n",
            "a:a\n",
            "g:g\n",
            "a:a\n",
            "i:i\n",
            "n:n\n",
            "s:s\n",
            "t:t\n",
            " : \n",
            "E:E\n",
            "n:n\n",
            "g:g\n",
            "l:l\n",
            "a:a\n",
            "n:n\n",
            "d:d\n",
            ".:.\n",
            " : \n",
            "H:H\n",
            "e:e\n",
            " : \n",
            "p:p\n",
            "l:l\n",
            "a:a\n",
            "y:y\n",
            "e:e\n",
            "d:d\n",
            " : \n",
            "b:b\n",
            "e:e\n",
            "a:a\n",
            "u:u\n",
            "t:t\n",
            "i:i\n",
            "f:f\n",
            "u:u\n",
            "l:l\n",
            "l:l\n",
            "y:y\n",
            " : \n",
            "a:a\n",
            "n:n\n",
            "d:d\n",
            " : \n",
            "f:f\n",
            "a:a\n",
            "n:n\n",
            "s:s\n",
            " : \n",
            "a:a\n",
            "r:r\n",
            "e:e\n",
            " : \n",
            "c:c\n",
            "h:h\n",
            "e:e\n",
            "e:e\n",
            "r:r\n",
            "i:i\n",
            "n:n\n",
            "g:g\n",
            " : \n",
            "w:w\n",
            "i:i\n",
            "t:t\n",
            "h:h\n",
            " : \n",
            "l:l\n",
            "o:o\n",
            "a:a\n",
            "d:d\n",
            "s:s\n",
            " : \n",
            "o:o\n",
            "f:f\n",
            " : \n",
            "h:h\n",
            "a:a\n",
            "p:p\n",
            "p:p\n",
            "i:i\n",
            "n:n\n",
            "e:e\n",
            "s:s\n",
            "s:s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeRMaBP1s7Vr"
      },
      "source": [
        ""
      ],
      "execution_count": 117,
      "outputs": []
    }
  ]
}